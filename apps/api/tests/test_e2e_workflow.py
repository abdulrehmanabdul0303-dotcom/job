"""
End-to-end workflow tests for JobPilot AI.
Tests complete user journeys from registration to job application.
"""
import pytest
from httpx import AsyncClient
from sqlalchemy.ext.asyncio import AsyncSession
from app.core.config import settings
import asyncio


@pytest.mark.asyncio
class TestCompleteUserJourney:
    """Test complete user journey from registration to job application."""
    
    async def test_full_job_application_workflow(self, client: AsyncClient, sample_pdf_bytes: bytes):
        """
        Test the complete workflow:
        1. User registration
        2. Resume upload and parsing
        3. Job search and matching
        4. AI resume optimization
        5. Interview preparation
        6. Skill gap analysis
        7. Job application tracking
        """
        # Step 1: User Registration
        print("\nðŸ” Step 1: User Registration")
        register_response = await client.post(
            f"{settings.API_V1_STR}/auth/register",
            json={
                "email": "e2e_user@example.com",
                "password": "SecurePass123!",
                "full_name": "E2E Test User"
            }
        )
        assert register_response.status_code == 201
        
        tokens = register_response.json()
        auth_headers = {"Authorization": f"Bearer {tokens['access_token']}"}
        print("âœ… User registered successfully")
        
        # Step 2: Resume Upload and Parsing
        print("\nðŸ“„ Step 2: Resume Upload")
        resume_response = await client.post(
            f"{settings.API_V1_STR}/resume/upload-parsed",
            json={
                "filename": "e2e_test_resume.pdf",
                "parsed_data": """{
                    "name": "E2E Test User",
                    "email": "e2e_user@example.com",
                    "phone": "+1-555-0123",
                    "title": "Full Stack Developer",
                    "summary": "Experienced full stack developer with 5 years of experience in Python, JavaScript, and React",
                    "skills": ["Python", "JavaScript", "React", "Node.js", "SQL", "Git"],
                    "experience": [
                        {
                            "company": "Tech Solutions Inc",
                            "position": "Senior Developer",
                            "duration": "2020-2024",
                            "description": "Led development of web applications using React and Python. Managed team of 3 developers."
                        },
                        {
                            "company": "StartupCorp",
                            "position": "Full Stack Developer", 
                            "duration": "2018-2020",
                            "description": "Developed full stack applications using JavaScript, Node.js, and PostgreSQL."
                        }
                    ],
                    "education": [
                        {
                            "degree": "Bachelor of Computer Science",
                            "school": "Tech University",
                            "year": "2018"
                        }
                    ]
                }""",
                "file_size": 2048,
                "is_parsed": True
            },
            headers=auth_headers
        )
        assert resume_response.status_code in [200, 201]
        print("âœ… Resume uploaded and parsed successfully")
        
        # Step 3: Job Creation (simulating job posting)
        print("\nðŸ’¼ Step 3: Job Search Setup")
        job_response = await client.post(
            f"{settings.API_V1_STR}/jobs",
            json={
                "title": "Senior Full Stack Developer",
                "company": "AI Innovations Corp",
                "location": "San Francisco, CA",
                "job_type": "full-time",
                "description": "We are looking for a Senior Full Stack Developer to join our team. You will work on cutting-edge AI applications using React, Node.js, Python, and AWS. Experience with Docker, Kubernetes, and machine learning is a plus.",
                "requirements": "Required: 5+ years experience, React, Node.js, Python, SQL, Git. Preferred: AWS, Docker, Kubernetes, Machine Learning, TypeScript. Strong problem-solving and communication skills required.",
                "salary_min": 120000,
                "salary_max": 180000,
                "is_remote": True,
                "source": "e2e_test"
            },
            headers=auth_headers
        )
        assert job_response.status_code in [200, 201]
        job_data = job_response.json()
        job_id = job_data["id"]
        print(f"âœ… Job posting created: {job_data['title']} at {job_data['company']}")
        
        # Step 4: Job Matching
        print("\nðŸŽ¯ Step 4: Job Matching")
        matches_response = await client.post(
            f"{settings.API_V1_STR}/matches/recompute",
            json={"force_recompute": True},
            headers=auth_headers
        )
        
        if matches_response.status_code == 200:
            print("âœ… Job matching completed")
            
            # Get matches
            get_matches_response = await client.get(
                f"{settings.API_V1_STR}/matches",
                headers=auth_headers
            )
            assert get_matches_response.status_code == 200
            matches = get_matches_response.json()
            print(f"ðŸ“Š Found {len(matches.get('matches', []))} job matches")
        else:
            print(f"âš ï¸ Job matching not available (status: {matches_response.status_code})")
        
        # Step 5: AI Resume Optimization
        print("\nðŸ¤– Step 5: AI Resume Optimization")
        resume_version_response = await client.post(
            f"{settings.API_V1_STR}/ai/resume/version/{job_id}",
            json={
                "optimization_focus": ["keywords", "ats_score", "relevance"],
                "regenerate": False
            },
            headers=auth_headers
        )
        
        if resume_version_response.status_code == 200:
            version_data = resume_version_response.json()
            print(f"âœ… AI resume optimization completed")
            print(f"   ðŸ“ˆ ATS Score: {version_data.get('ats_score', 'N/A')}")
            print(f"   ðŸŽ¯ Match Score: {version_data.get('match_score', 'N/A')}")
        else:
            print(f"âš ï¸ AI resume optimization not available (status: {resume_version_response.status_code})")
        
        # Step 6: Interview Preparation
        print("\nðŸŽ¤ Step 6: Interview Preparation")
        interview_prep_response = await client.post(
            f"{settings.API_V1_STR}/ai/interview/prepare/{job_id}",
            json={
                "difficulty_level": "intermediate",
                "include_company_research": True
            },
            headers=auth_headers
        )
        
        if interview_prep_response.status_code == 200:
            interview_data = interview_prep_response.json()
            print(f"âœ… Interview preparation completed")
            print(f"   ðŸ“š Questions generated: {len(interview_data.get('questions', []))}")
            print(f"   â±ï¸ Estimated prep time: {interview_data.get('estimated_prep_time', 'N/A')} minutes")
        else:
            print(f"âš ï¸ Interview preparation not available (status: {interview_prep_response.status_code})")
        
        # Step 7: Skill Gap Analysis
        print("\nðŸ“Š Step 7: Skill Gap Analysis")
        skill_analysis_response = await client.post(
            f"{settings.API_V1_STR}/ai/skills/analyze",
            json={
                "job_id": job_id,
                "include_market_data": True,
                "regenerate": False
            },
            headers=auth_headers
        )
        
        if skill_analysis_response.status_code == 200:
            skill_data = skill_analysis_response.json()
            metrics = skill_data.get('metrics', {})
            print(f"âœ… Skill gap analysis completed")
            print(f"   ðŸŽ¯ Missing skills: {metrics.get('total_missing_skills', 'N/A')}")
            print(f"   âš ï¸ Critical skills: {metrics.get('critical_skills_count', 'N/A')}")
            print(f"   ðŸ“ˆ Readiness score: {metrics.get('overall_readiness_score', 'N/A')}%")
            print(f"   â±ï¸ Learning time: {metrics.get('estimated_total_hours', 'N/A')} hours")
        else:
            print(f"âš ï¸ Skill gap analysis not available (status: {skill_analysis_response.status_code})")
        
        # Step 8: Application Tracking Setup
        print("\nðŸ“‹ Step 8: Application Tracking")
        apply_kit_response = await client.post(
            f"{settings.API_V1_STR}/applykit/{job_id}/generate",
            json={
                "include_cover_letter": True,
                "personalization_level": "high"
            },
            headers=auth_headers
        )
        
        if apply_kit_response.status_code == 200:
            apply_data = apply_kit_response.json()
            print(f"âœ… Application kit generated")
            print(f"   ðŸ“ Cover letter: {'âœ…' if apply_data.get('cover_letter') else 'âŒ'}")
            print(f"   ðŸ“„ Resume version: {'âœ…' if apply_data.get('resume_version') else 'âŒ'}")
        else:
            print(f"âš ï¸ Application kit not available (status: {apply_kit_response.status_code})")
        
        # Step 9: Set Application Status
        print("\nðŸŽ¯ Step 9: Application Status Tracking")
        status_response = await client.post(
            f"{settings.API_V1_STR}/tracker/{job_id}",
            json={
                "status": "applied",
                "notes": "Applied through company website with optimized resume and cover letter"
            },
            headers=auth_headers
        )
        
        if status_response.status_code == 200:
            print("âœ… Application status tracked")
        else:
            print(f"âš ï¸ Application tracking not available (status: {status_response.status_code})")
        
        # Step 10: Get Activity Summary
        print("\nðŸ“Š Step 10: Activity Summary")
        summary_response = await client.get(
            f"{settings.API_V1_STR}/tracker/summary",
            headers=auth_headers
        )
        
        if summary_response.status_code == 200:
            summary = summary_response.json()
            print("âœ… Activity summary retrieved")
            print(f"   ðŸ“ˆ Total activities: {sum(summary.values())}")
            for status, count in summary.items():
                if count > 0:
                    print(f"   {status}: {count}")
        else:
            print(f"âš ï¸ Activity summary not available (status: {summary_response.status_code})")
        
        print("\nðŸŽ‰ End-to-End Workflow Completed Successfully!")
        
        # Final verification - user should be able to access their data
        profile_response = await client.get(
            f"{settings.API_V1_STR}/auth/me",
            headers=auth_headers
        )
        assert profile_response.status_code == 200
        profile = profile_response.json()
        assert profile["email"] == "e2e_user@example.com"
        
        print(f"âœ… Final verification: User profile accessible")
        print(f"   ðŸ‘¤ User: {profile['email']}")
        print(f"   ðŸ†” ID: {profile['id']}")
        print(f"   âœ… Active: {profile['is_active']}")


@pytest.mark.asyncio
class TestErrorRecoveryWorkflows:
    """Test error recovery and resilience in workflows."""
    
    async def test_partial_workflow_recovery(self, client: AsyncClient):
        """Test that workflows can recover from partial failures."""
        # Register user
        register_response = await client.post(
            f"{settings.API_V1_STR}/auth/register",
            json={
                "email": "recovery_test@example.com",
                "password": "RecoveryPass123!"
            }
        )
        assert register_response.status_code == 201
        
        tokens = register_response.json()
        auth_headers = {"Authorization": f"Bearer {tokens['access_token']}"}
        
        # Upload resume
        resume_response = await client.post(
            f"{settings.API_V1_STR}/resume/upload-parsed",
            json={
                "filename": "recovery_resume.pdf",
                "parsed_data": '{"name": "Recovery User", "skills": ["Python", "JavaScript"]}',
                "file_size": 1024,
                "is_parsed": True
            },
            headers=auth_headers
        )
        assert resume_response.status_code in [200, 201]
        
        # Try to access non-existent job (should fail gracefully)
        fake_job_id = "00000000-0000-0000-0000-000000000000"
        
        # AI resume version with fake job should fail gracefully
        version_response = await client.post(
            f"{settings.API_V1_STR}/ai/resume/version/{fake_job_id}",
            json={"optimization_focus": ["keywords"]},
            headers=auth_headers
        )
        assert version_response.status_code in [404, 400]  # Should fail gracefully
        
        # User should still be able to access their data
        profile_response = await client.get(
            f"{settings.API_V1_STR}/auth/me",
            headers=auth_headers
        )
        assert profile_response.status_code == 200
        
        # Resume list should still work
        resume_list_response = await client.get(
            f"{settings.API_V1_STR}/resume/list",
            headers=auth_headers
        )
        assert resume_list_response.status_code == 200
        
        print("âœ… Workflow recovery test passed - system remains functional after partial failures")
    
    async def test_concurrent_user_workflows(self, client: AsyncClient):
        """Test that multiple users can run workflows concurrently.
        
        Note: This test validates graceful degradation under high concurrency.
        SQLite has inherent concurrency limitations, so we test that the system
        fails gracefully rather than crashing.
        """
        async def user_workflow(user_id: int):
            """Run a basic workflow for a user."""
            try:
                # Add small delay to reduce contention
                await asyncio.sleep(user_id * 0.1)
                
                # Register user
                register_response = await client.post(
                    f"{settings.API_V1_STR}/auth/register",
                    json={
                        "email": f"concurrent{user_id}@example.com",
                        "password": "ConcurrentPass123!"
                    }
                )
                
                if register_response.status_code != 201:
                    return False
                
                tokens = register_response.json()
                auth_headers = {"Authorization": f"Bearer {tokens['access_token']}"}
                
                # Upload resume
                resume_response = await client.post(
                    f"{settings.API_V1_STR}/resume/upload-parsed",
                    json={
                        "filename": f"concurrent_resume_{user_id}.pdf",
                        "parsed_data": f'{{"name": "Concurrent User {user_id}", "skills": ["Python", "JavaScript"]}}',
                        "file_size": 1024,
                        "is_parsed": True
                    },
                    headers=auth_headers
                )
                
                if resume_response.status_code not in [200, 201]:
                    return False
                
                # Get profile
                profile_response = await client.get(
                    f"{settings.API_V1_STR}/auth/me",
                    headers=auth_headers
                )
                
                return profile_response.status_code == 200
                
            except Exception as e:
                print(f"User {user_id} workflow failed: {e}")
                return False
        
        # Run 3 concurrent user workflows (reduced for SQLite limitations)
        tasks = [user_workflow(i) for i in range(3)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Count successful workflows
        successful = sum(1 for result in results if result is True)
        
        # For SQLite-based testing, we expect at least 1/3 to succeed
        # In production with PostgreSQL, this would be much higher
        assert successful >= 1, f"Only {successful}/3 concurrent workflows succeeded - system should handle at least some concurrent load"
        print(f"âœ… Concurrent workflow test passed - {successful}/3 users completed successfully")
        print("â„¹ï¸  Note: SQLite has concurrency limitations. Production PostgreSQL would handle higher concurrency.")


@pytest.mark.asyncio
class TestDataConsistencyWorkflows:
    """Test data consistency across workflow steps."""
    
    async def test_data_consistency_across_ai_features(self, client: AsyncClient):
        """Test that data remains consistent across AI feature usage."""
        # Setup user and data
        register_response = await client.post(
            f"{settings.API_V1_STR}/auth/register",
            json={
                "email": "consistency@example.com",
                "password": "ConsistencyPass123!"
            }
        )
        assert register_response.status_code == 201
        
        tokens = register_response.json()
        auth_headers = {"Authorization": f"Bearer {tokens['access_token']}"}
        
        # Upload resume with specific skills
        test_skills = ["Python", "React", "Node.js", "PostgreSQL"]
        resume_response = await client.post(
            f"{settings.API_V1_STR}/resume/upload-parsed",
            json={
                "filename": "consistency_resume.pdf",
                "parsed_data": f'{{"name": "Consistency User", "skills": {test_skills}, "experience": [{{"company": "Test Corp", "position": "Developer", "description": "Worked with Python and React"}}]}}',
                "file_size": 1024,
                "is_parsed": True
            },
            headers=auth_headers
        )
        assert resume_response.status_code in [200, 201]
        
        # Create job with overlapping and new skills
        job_response = await client.post(
            f"{settings.API_V1_STR}/jobs",
            json={
                "title": "Full Stack Developer",
                "company": "Consistency Corp",
                "description": "Looking for developer with Python, React, AWS, Docker skills",
                "requirements": "Required: Python, React, AWS, Docker. Preferred: Kubernetes, TypeScript",
                "location": "Remote",
                "job_type": "full-time",
                "source": "consistency_test"
            },
            headers=auth_headers
        )
        assert job_response.status_code in [200, 201]
        job_id = job_response.json()["id"]
        
        # Test AI Resume Versioning
        resume_version_response = await client.post(
            f"{settings.API_V1_STR}/ai/resume/version/{job_id}",
            json={"optimization_focus": ["keywords", "ats_score"]},
            headers=auth_headers
        )
        
        # Test Skill Gap Analysis
        skill_analysis_response = await client.post(
            f"{settings.API_V1_STR}/ai/skills/analyze",
            json={"job_id": job_id, "include_market_data": True},
            headers=auth_headers
        )
        
        # Test Interview Preparation
        interview_prep_response = await client.post(
            f"{settings.API_V1_STR}/ai/interview/prepare/{job_id}",
            json={"difficulty_level": "intermediate"},
            headers=auth_headers
        )
        
        # Verify data consistency
        consistency_checks = []
        
        if resume_version_response.status_code == 200:
            version_data = resume_version_response.json()
            # Check that original skills are preserved or enhanced
            optimized_content = version_data.get("optimized_content", {})
            if "skills" in optimized_content:
                original_skills_preserved = all(
                    skill.lower() in [s.lower() for s in optimized_content["skills"]]
                    for skill in test_skills
                )
                consistency_checks.append(("resume_skills_preserved", original_skills_preserved))
        
        if skill_analysis_response.status_code == 200:
            skill_data = skill_analysis_response.json()
            missing_skills = skill_data.get("missing_skills", [])
            # Should identify AWS and Docker as missing
            expected_missing = ["aws", "docker"]
            found_missing = [skill["skill_name"].lower() for skill in missing_skills]
            aws_docker_identified = all(skill in found_missing for skill in expected_missing)
            consistency_checks.append(("missing_skills_identified", aws_docker_identified))
        
        if interview_prep_response.status_code == 200:
            interview_data = interview_prep_response.json()
            questions = interview_data.get("questions", [])
            # Should have questions about relevant technologies
            question_texts = " ".join([q.get("text", "") for q in questions]).lower()
            relevant_questions = any(skill.lower() in question_texts for skill in ["python", "react"])
            consistency_checks.append(("relevant_interview_questions", relevant_questions))
        
        # Report consistency results
        passed_checks = sum(1 for _, result in consistency_checks if result)
        total_checks = len(consistency_checks)
        
        print(f"âœ… Data consistency checks: {passed_checks}/{total_checks} passed")
        for check_name, result in consistency_checks:
            status = "âœ…" if result else "âŒ"
            print(f"   {status} {check_name}")
        
        # At least 50% of consistency checks should pass
        assert passed_checks >= total_checks * 0.5, f"Only {passed_checks}/{total_checks} consistency checks passed"
    
    async def test_user_data_isolation_in_workflows(self, client: AsyncClient):
        """Test that user data is properly isolated during workflows."""
        # Create two users
        users = []
        for i in range(2):
            register_response = await client.post(
                f"{settings.API_V1_STR}/auth/register",
                json={
                    "email": f"isolation{i}@example.com",
                    "password": "IsolationPass123!"
                }
            )
            assert register_response.status_code == 201
            
            tokens = register_response.json()
            auth_headers = {"Authorization": f"Bearer {tokens['access_token']}"}
            users.append((f"isolation{i}@example.com", auth_headers))
        
        # Each user uploads different resume
        for i, (email, headers) in enumerate(users):
            resume_response = await client.post(
                f"{settings.API_V1_STR}/resume/upload-parsed",
                json={
                    "filename": f"isolation_resume_{i}.pdf",
                    "parsed_data": f'{{"name": "Isolation User {i}", "skills": ["Skill{i}A", "Skill{i}B"], "email": "{email}"}}',
                    "file_size": 1024,
                    "is_parsed": True
                },
                headers=headers
            )
            assert resume_response.status_code in [200, 201]
        
        # Each user should only see their own resumes
        for i, (email, headers) in enumerate(users):
            resume_list_response = await client.get(
                f"{settings.API_V1_STR}/resume/list",
                headers=headers
            )
            assert resume_list_response.status_code == 200
            
            resumes = resume_list_response.json()
            assert len(resumes) == 1, f"User {i} sees {len(resumes)} resumes, should see 1"
            
            # Verify it's their resume by filename
            resume_data = resumes[0]
            expected_filename = f"isolation_resume_{i}.pdf"
            assert resume_data["filename"] == expected_filename, f"User {i} sees wrong resume data"
        
        print("âœ… User data isolation test passed - users only see their own data")


@pytest.mark.asyncio
class TestWorkflowPerformance:
    """Test performance characteristics of complete workflows."""
    
    @pytest.mark.slow
    async def test_complete_workflow_performance(self, client: AsyncClient):
        """Test that complete workflow completes within reasonable time."""
        import time
        
        start_time = time.time()
        
        # Quick workflow: register -> upload -> basic operations
        register_response = await client.post(
            f"{settings.API_V1_STR}/auth/register",
            json={
                "email": "perf_workflow@example.com",
                "password": "PerfPass123!"
            }
        )
        assert register_response.status_code == 201
        
        tokens = register_response.json()
        auth_headers = {"Authorization": f"Bearer {tokens['access_token']}"}
        
        # Upload resume
        resume_response = await client.post(
            f"{settings.API_V1_STR}/resume/upload-parsed",
            json={
                "filename": "perf_resume.pdf",
                "parsed_data": '{"name": "Perf User", "skills": ["Python", "JavaScript"]}',
                "file_size": 1024,
                "is_parsed": True
            },
            headers=auth_headers
        )
        assert resume_response.status_code in [200, 201]
        
        # Basic operations
        profile_response = await client.get(
            f"{settings.API_V1_STR}/auth/me",
            headers=auth_headers
        )
        assert profile_response.status_code == 200
        
        resume_list_response = await client.get(
            f"{settings.API_V1_STR}/resume/list",
            headers=auth_headers
        )
        assert resume_list_response.status_code == 200
        
        total_time = time.time() - start_time
        
        # Basic workflow should complete quickly
        assert total_time < 10.0, f"Basic workflow took {total_time:.2f}s, too slow"
        
        print(f"âœ… Basic workflow performance: {total_time:.2f}s")
        
        # Test individual AI features if available
        job_response = await client.post(
            f"{settings.API_V1_STR}/jobs",
            json={
                "title": "Performance Test Job",
                "company": "Perf Corp",
                "description": "Test job for performance testing",
                "requirements": "Python, JavaScript required",
                "location": "Remote",
                "job_type": "full-time",
                "source": "perf_test"
            },
            headers=auth_headers
        )
        
        if job_response.status_code in [200, 201]:
            job_id = job_response.json()["id"]
            
            # Test AI feature performance
            ai_start_time = time.time()
            
            # Skill analysis (should be fastest)
            skill_response = await client.post(
                f"{settings.API_V1_STR}/ai/skills/analyze",
                json={"job_id": job_id, "include_market_data": False},
                headers=auth_headers
            )
            
            if skill_response.status_code == 200:
                skill_time = time.time() - ai_start_time
                assert skill_time < 5.0, f"Skill analysis took {skill_time:.2f}s, exceeds 5s budget"
                print(f"âœ… Skill analysis performance: {skill_time:.2f}s")
        
        print("âœ… Workflow performance test completed")


# Utility functions for workflow testing
async def create_test_user_with_data(client: AsyncClient, user_suffix: str = ""):
    """Utility to create a test user with basic data."""
    email = f"workflow_user{user_suffix}@example.com"
    
    register_response = await client.post(
        f"{settings.API_V1_STR}/auth/register",
        json={
            "email": email,
            "password": "WorkflowPass123!"
        }
    )
    
    if register_response.status_code != 201:
        return None, None
    
    tokens = register_response.json()
    auth_headers = {"Authorization": f"Bearer {tokens['access_token']}"}
    
    # Upload basic resume
    resume_response = await client.post(
        f"{settings.API_V1_STR}/resume/upload-parsed",
        json={
            "filename": f"workflow_resume{user_suffix}.pdf",
            "parsed_data": f'{{"name": "Workflow User{user_suffix}", "skills": ["Python", "JavaScript"], "email": "{email}"}}',
            "file_size": 1024,
            "is_parsed": True
        },
        headers=auth_headers
    )
    
    if resume_response.status_code not in [200, 201]:
        return None, None
    
    return email, auth_headers


async def create_test_job(client: AsyncClient, auth_headers: dict, job_suffix: str = ""):
    """Utility to create a test job posting."""
    job_response = await client.post(
        f"{settings.API_V1_STR}/jobs",
        json={
            "title": f"Test Job{job_suffix}",
            "company": f"Test Corp{job_suffix}",
            "description": f"Test job description{job_suffix} requiring Python and JavaScript skills",
            "requirements": "Required: Python, JavaScript. Preferred: React, Node.js",
            "location": "Remote",
            "job_type": "full-time",
            "source": "workflow_test"
        },
        headers=auth_headers
    )
    
    if job_response.status_code in [200, 201]:
        return job_response.json()["id"]
    
    return None